{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Importing libraries and loading data from database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bisma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bisma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bisma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bisma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger', 'stopwords'])\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "\n",
    "df = pd.read_sql_table(\"disaster_messages\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0        0      0            0             0                 0      ...         \n",
       "1        0      0            1             0                 0      ...         \n",
       "2        0      0            0             0                 0      ...         \n",
       "3        1      0            1             0                 1      ...         \n",
       "4        0      0            0             0                 0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning feature and target variables\n",
    "X = df['message']\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4    says: west side of Haiti, rest of the country ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing feature variable\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water      ...        aid_centers  \\\n",
       "0                  0         0         0      0      ...                  0   \n",
       "1                  0         0         0      0      ...                  0   \n",
       "2                  0         0         0      0      ...                  0   \n",
       "3                  0         0         0      0      ...                  0   \n",
       "4                  0         0         0      0      ...                  0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  \n",
       "2     0              0              0  \n",
       "3     0              0              0  \n",
       "4     0              0              0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing target variables\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'water', 'food', 'shelter', 'clothing', 'money', 'missing_people',\n",
       "       'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport',\n",
       "       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n",
       "       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n",
       "       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
       "       'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving category names\n",
    "category_names = y.columns\n",
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water      ...        aid_centers  \\\n",
       "0                  0         0         0      0      ...                  0   \n",
       "1                  0         0         0      0      ...                  0   \n",
       "2                  0         0         0      0      ...                  0   \n",
       "3                  0         0         0      0      ...                  0   \n",
       "4                  0         0         0      0      ...                  0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  \n",
       "2     0              0              0  \n",
       "3     0              0              0  \n",
       "4     0              0              0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling NaN values with 0 so tha the model that doesn't throw errors. \n",
    "Y = Y.fillna(0)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN means that the message doesn't belong to this category, so we can easily replace it with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Writing a tokenization function to process our text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Removing urls\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "        \n",
    "    # Removing punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # Tokenizing the data\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remocing stop words\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    tokens = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    # Lemmatizing the data\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building a machine learning pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the traning data to the pipeline\n",
    "pipeline_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the results\n",
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.94      0.89      3993\n",
      "               request       0.84      0.49      0.62       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.76      0.69      0.73      2146\n",
      "          medical_help       0.67      0.11      0.20       384\n",
      "      medical_products       0.74      0.11      0.18       237\n",
      "     search_and_rescue       0.45      0.03      0.06       147\n",
      "              security       0.00      0.00      0.00       104\n",
      "              military       0.75      0.06      0.11       159\n",
      "                 water       0.88      0.38      0.53       336\n",
      "                  food       0.85      0.65      0.73       565\n",
      "               shelter       0.88      0.38      0.53       464\n",
      "              clothing       0.82      0.12      0.20        78\n",
      "                 money       1.00      0.04      0.08       124\n",
      "        missing_people       0.00      0.00      0.00        52\n",
      "              refugees       0.45      0.03      0.06       169\n",
      "                 death       0.86      0.19      0.30       232\n",
      "             other_aid       0.60      0.04      0.07       705\n",
      "infrastructure_related       0.00      0.00      0.00       348\n",
      "             transport       0.76      0.08      0.15       237\n",
      "             buildings       0.80      0.13      0.22       271\n",
      "           electricity       1.00      0.02      0.03       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.00      0.00      0.00        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.00      0.00      0.00        68\n",
      "  other_infrastructure       0.00      0.00      0.00       229\n",
      "       weather_related       0.86      0.70      0.77      1418\n",
      "                floods       0.88      0.48      0.62       413\n",
      "                 storm       0.79      0.55      0.65       476\n",
      "                  fire       1.00      0.02      0.04        54\n",
      "            earthquake       0.91      0.81      0.85       475\n",
      "                  cold       0.81      0.13      0.22       100\n",
      "         other_weather       0.44      0.03      0.05       284\n",
      "         direct_report       0.79      0.37      0.51      1025\n",
      "\n",
      "             micro avg       0.82      0.54      0.65     16478\n",
      "             macro avg       0.58      0.22      0.27     16478\n",
      "          weighted avg       0.75      0.54      0.58     16478\n",
      "           samples avg       0.66      0.48      0.51     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report category-wise and overall\n",
    "print(classification_report(y_test, y_pred_rf, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest took a lot of time to train and predict the data and gave an weighted average F-1 score of 0.58, which is decent enough for a multi-class classification problem. Let's see if we can do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svc = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(SVC(kernel='linear')))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=SVC(C=1.0, break_ties=False,\n",
       "                                                     cache_size=200,\n",
       "                                                     class_weight=None,\n",
       "                                                     coef0=0.0,\n",
       "                                                     decision_function_shape='ovr',\n",
       "                                                     degree=3, gamma='scale',\n",
       "                                                     kernel='linear',\n",
       "                                                     max_iter=-1,\n",
       "                                                     probability=False,\n",
       "                                                     random_state=None,\n",
       "                                                     shrinking=True, tol=0.001,\n",
       "                                                     verbose=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = pipeline_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.93      0.89      3993\n",
      "               request       0.78      0.60      0.68       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.75      0.70      0.72      2146\n",
      "          medical_help       0.59      0.24      0.34       384\n",
      "      medical_products       0.70      0.29      0.41       237\n",
      "     search_and_rescue       0.63      0.13      0.21       147\n",
      "              security       0.00      0.00      0.00       104\n",
      "              military       0.64      0.31      0.42       159\n",
      "                 water       0.75      0.68      0.71       336\n",
      "                  food       0.81      0.75      0.78       565\n",
      "               shelter       0.84      0.57      0.68       464\n",
      "              clothing       0.67      0.44      0.53        78\n",
      "                 money       0.58      0.12      0.20       124\n",
      "        missing_people       0.82      0.17      0.29        52\n",
      "              refugees       0.61      0.21      0.31       169\n",
      "                 death       0.80      0.53      0.64       232\n",
      "             other_aid       0.63      0.09      0.16       705\n",
      "infrastructure_related       0.33      0.00      0.01       348\n",
      "             transport       0.82      0.24      0.37       237\n",
      "             buildings       0.71      0.32      0.44       271\n",
      "           electricity       0.66      0.18      0.29       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.00      0.00      0.00        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.00      0.00      0.00        68\n",
      "  other_infrastructure       0.00      0.00      0.00       229\n",
      "       weather_related       0.86      0.73      0.79      1418\n",
      "                floods       0.90      0.54      0.68       413\n",
      "                 storm       0.75      0.63      0.68       476\n",
      "                  fire       0.75      0.28      0.41        54\n",
      "            earthquake       0.90      0.81      0.85       475\n",
      "                  cold       0.62      0.25      0.36       100\n",
      "         other_weather       0.60      0.10      0.17       284\n",
      "         direct_report       0.70      0.49      0.57      1025\n",
      "\n",
      "             micro avg       0.80      0.60      0.69     16478\n",
      "             macro avg       0.57      0.32      0.39     16478\n",
      "          weighted avg       0.74      0.60      0.64     16478\n",
      "           samples avg       0.63      0.51      0.52     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svc, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC too way too much time as compared to the Random Forest and may not be an approporate choice for the real-time analysis or/and the dataset is huge. However, it performed better than Random Forest and gave an weighted average F-1 score of 0.64. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_knn = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(KNeighborsClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at 0x000001F224DC4950>,\n",
       "                                 vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=KNeighborsClassifier(algorithm='auto',\n",
       "                                                                      leaf_size=30,\n",
       "                                                                      metric='minkowski',\n",
       "                                                                      metric_params=None,\n",
       "                                                                      n_jobs=None,\n",
       "                                                                      n_neighbors=5,\n",
       "                                                                      p=2,\n",
       "                                                                      weights='uniform'),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = pipeline_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.78      0.98      0.87      3993\n",
      "               request       0.80      0.08      0.15       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.79      0.04      0.08      2146\n",
      "          medical_help       0.00      0.00      0.00       384\n",
      "      medical_products       0.40      0.01      0.02       237\n",
      "     search_and_rescue       1.00      0.01      0.03       147\n",
      "              security       0.00      0.00      0.00       104\n",
      "              military       0.00      0.00      0.00       159\n",
      "                 water       0.80      0.02      0.05       336\n",
      "                  food       0.82      0.05      0.10       565\n",
      "               shelter       0.77      0.04      0.08       464\n",
      "              clothing       1.00      0.01      0.03        78\n",
      "                 money       1.00      0.02      0.03       124\n",
      "        missing_people       0.00      0.00      0.00        52\n",
      "              refugees       0.00      0.00      0.00       169\n",
      "                 death       1.00      0.02      0.04       232\n",
      "             other_aid       0.48      0.02      0.03       705\n",
      "infrastructure_related       1.00      0.00      0.01       348\n",
      "             transport       0.00      0.00      0.00       237\n",
      "             buildings       1.00      0.02      0.04       271\n",
      "           electricity       0.00      0.00      0.00       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.00      0.00      0.00        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.00      0.00      0.00        68\n",
      "  other_infrastructure       1.00      0.00      0.01       229\n",
      "       weather_related       0.83      0.07      0.12      1418\n",
      "                floods       1.00      0.00      0.00       413\n",
      "                 storm       0.86      0.01      0.02       476\n",
      "                  fire       0.00      0.00      0.00        54\n",
      "            earthquake       0.85      0.17      0.28       475\n",
      "                  cold       0.00      0.00      0.00       100\n",
      "         other_weather       1.00      0.01      0.03       284\n",
      "         direct_report       0.68      0.06      0.10      1025\n",
      "\n",
      "             micro avg       0.78      0.27      0.40     16478\n",
      "             macro avg       0.51      0.05      0.06     16478\n",
      "          weighted avg       0.72      0.27      0.27     16478\n",
      "           samples avg       0.74      0.34      0.41     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knn, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN took very less time as it should have done. It is a lazy algorithm and doesn't really learn anything from the data as it just memorizes the data. That's why it performed very poorly and gave an weighted average F-1 score of 0.27. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gbc = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                                            max_depth=3,\n",
       "                                                                            max_features=None,\n",
       "                                                                            max_leaf_nodes=None,\n",
       "                                                                            min_impurity_decrease=0.0,\n",
       "                                                                            min_impurity_split=None,\n",
       "                                                                            min_samples_leaf=1,\n",
       "                                                                            min_samples_split=2,\n",
       "                                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                                            n_estimators=100,\n",
       "                                                                            n_iter_no_change=None,\n",
       "                                                                            presort='deprecated',\n",
       "                                                                            random_state=None,\n",
       "                                                                            subsample=1.0,\n",
       "                                                                            tol=0.0001,\n",
       "                                                                            validation_fraction=0.1,\n",
       "                                                                            verbose=0,\n",
       "                                                                            warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = pipeline_gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.79      0.98      0.87      3993\n",
      "               request       0.83      0.48      0.61       925\n",
      "                 offer       0.05      0.04      0.04        28\n",
      "           aid_related       0.78      0.58      0.67      2146\n",
      "          medical_help       0.62      0.21      0.32       384\n",
      "      medical_products       0.67      0.30      0.41       237\n",
      "     search_and_rescue       0.30      0.17      0.22       147\n",
      "              security       0.18      0.09      0.12       104\n",
      "              military       0.62      0.28      0.39       159\n",
      "                 water       0.75      0.65      0.69       336\n",
      "                  food       0.78      0.79      0.79       565\n",
      "               shelter       0.84      0.58      0.69       464\n",
      "              clothing       0.51      0.46      0.48        78\n",
      "                 money       0.46      0.26      0.33       124\n",
      "        missing_people       0.17      0.21      0.19        52\n",
      "              refugees       0.41      0.28      0.34       169\n",
      "                 death       0.66      0.55      0.60       232\n",
      "             other_aid       0.62      0.09      0.15       705\n",
      "infrastructure_related       0.44      0.03      0.06       348\n",
      "             transport       0.67      0.26      0.38       237\n",
      "             buildings       0.68      0.31      0.43       271\n",
      "           electricity       0.46      0.22      0.30       114\n",
      "                 tools       0.07      0.06      0.07        32\n",
      "             hospitals       0.03      0.02      0.02        63\n",
      "                 shops       0.05      0.04      0.05        23\n",
      "           aid_centers       0.15      0.09      0.11        68\n",
      "  other_infrastructure       0.17      0.03      0.05       229\n",
      "       weather_related       0.88      0.63      0.73      1418\n",
      "                floods       0.89      0.56      0.69       413\n",
      "                 storm       0.78      0.62      0.69       476\n",
      "                  fire       0.35      0.31      0.33        54\n",
      "            earthquake       0.87      0.83      0.85       475\n",
      "                  cold       0.57      0.36      0.44       100\n",
      "         other_weather       0.53      0.13      0.21       284\n",
      "         direct_report       0.76      0.37      0.49      1025\n",
      "\n",
      "             micro avg       0.76      0.58      0.66     16478\n",
      "             macro avg       0.53      0.34      0.39     16478\n",
      "          weighted avg       0.73      0.58      0.62     16478\n",
      "           samples avg       0.66      0.52      0.54     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_gbc, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting performed better than Random Forest but to a lesser extent as compared to SVC. It gave an weighted average F-1 score of 0.62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ab = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at 0x000001F224DC4950>,\n",
       "                                 vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                                    base_estimator=None,\n",
       "                                                                    learning_rate=1.0,\n",
       "                                                                    n_estimators=50,\n",
       "                                                                    random_state=None),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ab = pipeline_ab.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.79      0.98      0.87      3993\n",
      "               request       0.77      0.52      0.62       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.77      0.62      0.68      2146\n",
      "          medical_help       0.60      0.29      0.39       384\n",
      "      medical_products       0.62      0.32      0.42       237\n",
      "     search_and_rescue       0.62      0.19      0.29       147\n",
      "              security       0.36      0.05      0.08       104\n",
      "              military       0.57      0.37      0.45       159\n",
      "                 water       0.77      0.67      0.72       336\n",
      "                  food       0.80      0.66      0.72       565\n",
      "               shelter       0.79      0.53      0.63       464\n",
      "              clothing       0.67      0.47      0.56        78\n",
      "                 money       0.54      0.34      0.42       124\n",
      "        missing_people       0.43      0.17      0.25        52\n",
      "              refugees       0.62      0.31      0.42       169\n",
      "                 death       0.72      0.46      0.56       232\n",
      "             other_aid       0.50      0.15      0.23       705\n",
      "infrastructure_related       0.39      0.09      0.14       348\n",
      "             transport       0.65      0.25      0.36       237\n",
      "             buildings       0.63      0.40      0.49       271\n",
      "           electricity       0.57      0.21      0.31       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.12      0.03      0.05        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.39      0.10      0.16        68\n",
      "  other_infrastructure       0.27      0.07      0.12       229\n",
      "       weather_related       0.87      0.64      0.74      1418\n",
      "                floods       0.87      0.59      0.70       413\n",
      "                 storm       0.76      0.57      0.65       476\n",
      "                  fire       0.42      0.15      0.22        54\n",
      "            earthquake       0.89      0.79      0.83       475\n",
      "                  cold       0.74      0.28      0.41       100\n",
      "         other_weather       0.47      0.13      0.20       284\n",
      "         direct_report       0.70      0.41      0.51      1025\n",
      "\n",
      "             micro avg       0.76      0.59      0.66     16478\n",
      "             macro avg       0.56      0.34      0.41     16478\n",
      "          weighted avg       0.72      0.59      0.63     16478\n",
      "           samples avg       0.66      0.53      0.54     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_ab, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive Boosting performed second best after SVC with  n weighted average F-1 score of 0.63."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 - XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(XGBClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                               booster='gbtree',\n",
       "                                                               colsample_bylevel=1,\n",
       "                                                               colsample_bynode=1,\n",
       "                                                               colsample_bytree=1,\n",
       "                                                               gamma=0,\n",
       "                                                               learning_rate=0.1,\n",
       "                                                               max_delta_step=0,\n",
       "                                                               max_depth=3,\n",
       "                                                               min_child_weight=1,\n",
       "                                                               missing=None,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=1,\n",
       "                                                               nthread=None,\n",
       "                                                               objective='binary:logistic',\n",
       "                                                               random_state=0,\n",
       "                                                               reg_alpha=0,\n",
       "                                                               reg_lambda=1,\n",
       "                                                               scale_pos_weight=1,\n",
       "                                                               seed=None,\n",
       "                                                               silent=None,\n",
       "                                                               subsample=1,\n",
       "                                                               verbosity=1),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = pipeline_ab.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.79      0.98      0.87      3993\n",
      "               request       0.77      0.52      0.62       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.77      0.62      0.68      2146\n",
      "          medical_help       0.60      0.29      0.39       384\n",
      "      medical_products       0.62      0.32      0.42       237\n",
      "     search_and_rescue       0.62      0.19      0.29       147\n",
      "              security       0.36      0.05      0.08       104\n",
      "              military       0.57      0.37      0.45       159\n",
      "                 water       0.77      0.67      0.72       336\n",
      "                  food       0.80      0.66      0.72       565\n",
      "               shelter       0.79      0.53      0.63       464\n",
      "              clothing       0.67      0.47      0.56        78\n",
      "                 money       0.54      0.34      0.42       124\n",
      "        missing_people       0.43      0.17      0.25        52\n",
      "              refugees       0.62      0.31      0.42       169\n",
      "                 death       0.72      0.46      0.56       232\n",
      "             other_aid       0.50      0.15      0.23       705\n",
      "infrastructure_related       0.39      0.09      0.14       348\n",
      "             transport       0.65      0.25      0.36       237\n",
      "             buildings       0.63      0.40      0.49       271\n",
      "           electricity       0.57      0.21      0.31       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.12      0.03      0.05        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.39      0.10      0.16        68\n",
      "  other_infrastructure       0.27      0.07      0.12       229\n",
      "       weather_related       0.87      0.64      0.74      1418\n",
      "                floods       0.87      0.59      0.70       413\n",
      "                 storm       0.76      0.57      0.65       476\n",
      "                  fire       0.42      0.15      0.22        54\n",
      "            earthquake       0.89      0.79      0.83       475\n",
      "                  cold       0.74      0.28      0.41       100\n",
      "         other_weather       0.47      0.13      0.20       284\n",
      "         direct_report       0.70      0.41      0.51      1025\n",
      "\n",
      "             micro avg       0.76      0.59      0.66     16478\n",
      "             macro avg       0.56      0.34      0.41     16478\n",
      "          weighted avg       0.72      0.59      0.63     16478\n",
      "           samples avg       0.66      0.53      0.54     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_xgb, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost performed same as AdaBoost with n weighted average F-1 score of 0.63."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(MultinomialNB()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at 0x000001F224DC4950>,\n",
       "                                 vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=MultinomialNB(alpha=1.0,\n",
       "                                                               class_prior=None,\n",
       "                                                               fit_prior=True),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = pipeline_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.78      0.99      0.87      3993\n",
      "               request       0.85      0.22      0.35       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.73      0.64      0.68      2146\n",
      "          medical_help       0.00      0.00      0.00       384\n",
      "      medical_products       0.00      0.00      0.00       237\n",
      "     search_and_rescue       0.00      0.00      0.00       147\n",
      "              security       0.00      0.00      0.00       104\n",
      "              military       0.00      0.00      0.00       159\n",
      "                 water       0.00      0.00      0.00       336\n",
      "                  food       0.76      0.03      0.06       565\n",
      "               shelter       0.00      0.00      0.00       464\n",
      "              clothing       0.00      0.00      0.00        78\n",
      "                 money       0.00      0.00      0.00       124\n",
      "        missing_people       0.00      0.00      0.00        52\n",
      "              refugees       0.00      0.00      0.00       169\n",
      "                 death       0.00      0.00      0.00       232\n",
      "             other_aid       0.00      0.00      0.00       705\n",
      "infrastructure_related       0.00      0.00      0.00       348\n",
      "             transport       0.00      0.00      0.00       237\n",
      "             buildings       0.00      0.00      0.00       271\n",
      "           electricity       0.00      0.00      0.00       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.00      0.00      0.00        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.00      0.00      0.00        68\n",
      "  other_infrastructure       0.00      0.00      0.00       229\n",
      "       weather_related       0.86      0.43      0.57      1418\n",
      "                floods       0.50      0.00      0.00       413\n",
      "                 storm       0.67      0.01      0.02       476\n",
      "                  fire       0.00      0.00      0.00        54\n",
      "            earthquake       0.92      0.13      0.22       475\n",
      "                  cold       0.00      0.00      0.00       100\n",
      "         other_weather       0.00      0.00      0.00       284\n",
      "         direct_report       0.79      0.18      0.30      1025\n",
      "\n",
      "             micro avg       0.78      0.39      0.52     16478\n",
      "             macro avg       0.20      0.08      0.09     16478\n",
      "          weighted avg       0.54      0.39      0.40     16478\n",
      "           samples avg       0.71      0.42      0.48     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_nb, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes performed poorly as compared to other algorithms and it only performed better than KNN. However, it is pretty fast and can be used for large datasets and real-time analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mdoel 8 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(LogisticRegression(solver = 'lbfgs')))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(C=1.0,\n",
       "                                                                    class_weight=None,\n",
       "                                                                    dual=False,\n",
       "                                                                    fit_intercept=True,\n",
       "                                                                    intercept_scaling=1,\n",
       "                                                                    l1_ratio=None,\n",
       "                                                                    max_iter=100,\n",
       "                                                                    multi_class='auto',\n",
       "                                                                    n_jobs=None,\n",
       "                                                                    penalty='l2',\n",
       "                                                                    random_state=None,\n",
       "                                                                    solver='lbfgs',\n",
       "                                                                    tol=0.0001,\n",
       "                                                                    verbose=0,\n",
       "                                                                    warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = pipeline_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.96      0.89      3993\n",
      "               request       0.81      0.53      0.64       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.77      0.67      0.72      2146\n",
      "          medical_help       0.65      0.17      0.27       384\n",
      "      medical_products       0.75      0.21      0.33       237\n",
      "     search_and_rescue       0.70      0.05      0.09       147\n",
      "              security       0.00      0.00      0.00       104\n",
      "              military       0.53      0.12      0.19       159\n",
      "                 water       0.80      0.50      0.62       336\n",
      "                  food       0.84      0.62      0.72       565\n",
      "               shelter       0.83      0.46      0.59       464\n",
      "              clothing       0.86      0.23      0.36        78\n",
      "                 money       0.56      0.08      0.14       124\n",
      "        missing_people       1.00      0.02      0.04        52\n",
      "              refugees       0.68      0.08      0.14       169\n",
      "                 death       0.83      0.28      0.41       232\n",
      "             other_aid       0.59      0.12      0.20       705\n",
      "infrastructure_related       0.64      0.03      0.05       348\n",
      "             transport       0.90      0.15      0.26       237\n",
      "             buildings       0.74      0.21      0.33       271\n",
      "           electricity       0.67      0.11      0.18       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.00      0.00      0.00        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.00      0.00      0.00        68\n",
      "  other_infrastructure       0.71      0.02      0.04       229\n",
      "       weather_related       0.86      0.65      0.74      1418\n",
      "                floods       0.91      0.43      0.59       413\n",
      "                 storm       0.79      0.46      0.58       476\n",
      "                  fire       1.00      0.02      0.04        54\n",
      "            earthquake       0.91      0.68      0.78       475\n",
      "                  cold       0.62      0.10      0.17       100\n",
      "         other_weather       0.47      0.03      0.06       284\n",
      "         direct_report       0.73      0.44      0.55      1025\n",
      "\n",
      "             micro avg       0.81      0.55      0.66     16478\n",
      "             macro avg       0.63      0.24      0.31     16478\n",
      "          weighted avg       0.77      0.55      0.60     16478\n",
      "           samples avg       0.67      0.49      0.52     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_lr, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Logistic Regression is a very simple algorithm, it seems to be a powerful one, outperforming many of the other advanced algorithms such as Random Forest. It gave and weighted avg. F-1 score of 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Improving our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above analysis that SVC performs the best out of all models tested above based on the weighted avg. F-1 score but it is very slow even with a 'linear' kernel. This might not be a good choice in case the dataset size increases in the future. Similarly XGBoost and AdaBoost perfomed almost similar to SVC, but are computationally expensive. So, let's choose Logistic Regression as our final model as it performs decent enough and is less computation expensive. Let's also tweak some of its parameters using Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf',\n",
       " 'clf__estimator',\n",
       " 'clf__estimator__C',\n",
       " 'clf__estimator__class_weight',\n",
       " 'clf__estimator__dual',\n",
       " 'clf__estimator__fit_intercept',\n",
       " 'clf__estimator__intercept_scaling',\n",
       " 'clf__estimator__l1_ratio',\n",
       " 'clf__estimator__max_iter',\n",
       " 'clf__estimator__multi_class',\n",
       " 'clf__estimator__n_jobs',\n",
       " 'clf__estimator__penalty',\n",
       " 'clf__estimator__random_state',\n",
       " 'clf__estimator__solver',\n",
       " 'clf__estimator__tol',\n",
       " 'clf__estimator__verbose',\n",
       " 'clf__estimator__warm_start',\n",
       " 'clf__n_jobs',\n",
       " 'memory',\n",
       " 'steps',\n",
       " 'tfidf',\n",
       " 'tfidf__norm',\n",
       " 'tfidf__smooth_idf',\n",
       " 'tfidf__sublinear_tf',\n",
       " 'tfidf__use_idf',\n",
       " 'vect',\n",
       " 'vect__analyzer',\n",
       " 'vect__binary',\n",
       " 'vect__decode_error',\n",
       " 'vect__dtype',\n",
       " 'vect__encoding',\n",
       " 'vect__input',\n",
       " 'vect__lowercase',\n",
       " 'vect__max_df',\n",
       " 'vect__max_features',\n",
       " 'vect__min_df',\n",
       " 'vect__ngram_range',\n",
       " 'vect__preprocessor',\n",
       " 'vect__stop_words',\n",
       " 'vect__strip_accents',\n",
       " 'vect__token_pattern',\n",
       " 'vect__tokenizer',\n",
       " 'vect__vocabulary',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pipeline_lr.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(...\n",
       "                                                                                           intercept_scaling=1,\n",
       "                                                                                           l1_ratio=None,\n",
       "                                                                                           max_iter=100,\n",
       "                                                                                           multi_class='auto',\n",
       "                                                                                           n_jobs=None,\n",
       "                                                                                           penalty='l2',\n",
       "                                                                                           random_state=None,\n",
       "                                                                                           solver='lbfgs',\n",
       "                                                                                           tol=0.0001,\n",
       "                                                                                           verbose=0,\n",
       "                                                                                           warm_start=False),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__estimator__solver': ['newton-cg', 'lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search CV\n",
    "parameters = {\n",
    "        'clf__estimator__solver': ['newton-cg', 'lbfgs'],\n",
    "    }\n",
    "\n",
    "cv_lr = GridSearchCV(pipeline_lr, param_grid=parameters)\n",
    "cv_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing our improved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(...\n",
       "                                                                                           intercept_scaling=1,\n",
       "                                                                                           l1_ratio=None,\n",
       "                                                                                           max_iter=100,\n",
       "                                                                                           multi_class='auto',\n",
       "                                                                                           n_jobs=None,\n",
       "                                                                                           penalty='l2',\n",
       "                                                                                           random_state=None,\n",
       "                                                                                           solver='lbfgs',\n",
       "                                                                                           tol=0.0001,\n",
       "                                                                                           verbose=0,\n",
       "                                                                                           warm_start=False),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__estimator__solver': ['newton-cg', 'lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running Grid Search - taking too much time\n",
    "cv_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = cv_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.96      0.89      3993\n",
      "               request       0.81      0.53      0.64       925\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.77      0.67      0.72      2146\n",
      "          medical_help       0.65      0.17      0.27       384\n",
      "      medical_products       0.75      0.21      0.33       237\n",
      "     search_and_rescue       0.70      0.05      0.09       147\n",
      "              security       0.00      0.00      0.00       104\n",
      "              military       0.53      0.12      0.19       159\n",
      "                 water       0.80      0.50      0.62       336\n",
      "                  food       0.84      0.62      0.72       565\n",
      "               shelter       0.83      0.46      0.59       464\n",
      "              clothing       0.86      0.23      0.36        78\n",
      "                 money       0.56      0.08      0.14       124\n",
      "        missing_people       1.00      0.02      0.04        52\n",
      "              refugees       0.68      0.08      0.14       169\n",
      "                 death       0.83      0.28      0.41       232\n",
      "             other_aid       0.59      0.12      0.20       705\n",
      "infrastructure_related       0.64      0.03      0.05       348\n",
      "             transport       0.90      0.15      0.26       237\n",
      "             buildings       0.74      0.21      0.33       271\n",
      "           electricity       0.67      0.11      0.18       114\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.00      0.00      0.00        63\n",
      "                 shops       0.00      0.00      0.00        23\n",
      "           aid_centers       0.00      0.00      0.00        68\n",
      "  other_infrastructure       0.71      0.02      0.04       229\n",
      "       weather_related       0.86      0.65      0.74      1418\n",
      "                floods       0.91      0.43      0.59       413\n",
      "                 storm       0.79      0.46      0.58       476\n",
      "                  fire       1.00      0.02      0.04        54\n",
      "            earthquake       0.91      0.68      0.78       475\n",
      "                  cold       0.62      0.10      0.17       100\n",
      "         other_weather       0.47      0.03      0.06       284\n",
      "         direct_report       0.73      0.44      0.55      1025\n",
      "\n",
      "             micro avg       0.81      0.55      0.66     16478\n",
      "             macro avg       0.63      0.24      0.31     16478\n",
      "          weighted avg       0.77      0.55      0.60     16478\n",
      "           samples avg       0.67      0.49      0.52     16478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\bisma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_lr, target_names = category_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running GridSearch, it performs same as running without it. It is partly because we haven't passed a lot of parameters to tune. If we have more computation resources, we can pass in some more parameters or even choose AdaBoost/XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exporting our model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv_lr, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) This seems to be an  imbalanced dataset as the distribution of classes present in the dataset is not unfiform, meaning number of data points available for different classes are differnt. This creates a bias as ML algorithms are built to minimize errors. Algorithms are much more likley to classify new observations to the majority class.\n",
    "\n",
    "We could do re-sampling in order to mitigate these problems through Over-sampling or Under-sampling. Over-sampling increases the samples in minority class  without losing any data but it is prone to Overfitting. This can be done using Synthetic Minority Over-sampling Technique (SMOTE) or Adaptive Synthetic (ADASYN). \n",
    "\n",
    "Under-sampling redcues the number of samples belonging to majority class, thus we lose some of the data that might be useful. This can be done using NearMiss-n, Tomek's link or Edited nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) We could check the correlation between different features and drop variables, which have high correlation as some of the models such as Naive Bayes assume that features are independent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) We could further fine-tune the model by experming with different hyper-paramters in the Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
